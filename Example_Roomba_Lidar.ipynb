{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Install Julia and POMDP.jl\n",
    "\n",
    "Please first install Julia and POMDP.jl (https://github.com/JuliaPOMDP/POMDPs.jl).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Include Julia packages and load the problem\n",
    "Several POMDP julia packages such as \"POMDPTools, POMDPModels\" are already included in planner.jl.\n",
    "\n",
    "If there is an error about uninstalled packages, please install them with \"pkg.add()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./ContinuousPOMCGS/Planner.jl\")\n",
    "using RoombaPOMDPs\n",
    "\n",
    "# --- Roomba Lidar---\n",
    "num_x_pts = 25 # or 41\n",
    "num_y_pts = 16 # or 26\n",
    "num_th_pts = 10 # or 20\n",
    "sspace = DiscreteRoombaStateSpace(num_x_pts,num_y_pts,num_th_pts)\n",
    "pomdp = RoombaPOMDP(sensor=Lidar(), mdp=RoombaMDP(config=3, sspace=sspace))\n",
    "\n",
    "# Note that actions(pomdp) and rand(actions(pomdp)) is not properly implemented in the current RoombaPOMDP.jl package\n",
    "# Thus, one has to either implement those two functions in RoombaPOMDPs to sample an action from the continous action space, or using the following configuration\n",
    "# In this example, we represent continuous ranges with a large number of discrete actions (1071 actions)\n",
    "max_speed = 5.0\n",
    "speed_interval = 0.1\n",
    "max_turn_rate = 1.0\n",
    "turn_rate_interval = 0.1\n",
    "action_space = vec([RoombaAct(v, om) for v in 0:speed_interval:max_speed, om in -max_turn_rate:turn_rate_interval:max_turn_rate])\n",
    "pomdp = RoombaPOMDP(sensor=Lidar(), mdp=RoombaMDP(config=3, aspace=action_space, v_max=max_speed, sspace=sspace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is an exmaple parameter configuraiton ##\n",
    "b0 = initialstate(pomdp) # Get POMDP's initial belief\n",
    "nb_process_samples = 10000\n",
    "max_b_gap = 0.3\n",
    "nb_particles_b0 = nb_process_samples\n",
    "c = 1.0\n",
    "nb_abstract_obs = 5\n",
    "epsilon = 0.1\n",
    "particles_b0, dict_weighted_b0 = InitContinuousActionPOMDP(pomdp, b0, nb_particles_b0)\n",
    "rmin, a_rmin = FindRLower(pomdp, b0, action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare $V_{mdp}$\n",
    "\n",
    "Here we use a Q-learning algorithm to compute $V_{MDP}$, one can also use other MDP solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table = Dict{Any, Dict{Int64, Float64}}()\n",
    "V_table = Dict{Any, Float64}()\n",
    "learning_rate = 0.9\n",
    "explore_rate = 0.7\n",
    "# Define the size of the subset action space for Q-learning\n",
    "subset_size = 20\n",
    "# Randomly choose a subset without replacement\n",
    "subset_actions = sample(action_space, subset_size, replace=false)\n",
    "Vmdp = Qlearning(Q_table, V_table, learning_rate, explore_rate, subset_actions, typemin(Float64), typemax(Float64))\n",
    "nb_episode_size = 10\n",
    "nb_max_episode = 5\n",
    "nb_sim = 10\n",
    "Training(Vmdp, nb_episode_size, nb_max_episode, nb_sim, epsilon, particles_b0, pomdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Init POMCGS and run the solver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1: Define POMCGS and fsc ---\n",
    "planner = ContinuousPlannerPOMCGS(rmin, Vmdp)\n",
    "planner._bool_APW = true # using action progressive widening\n",
    "InitPlannerParameters(planner, \n",
    "                    nb_process_samples, \n",
    "                    max_b_gap,\n",
    "                    c,\n",
    "                    discount(pomdp),\n",
    "                    # nb_abstract_samples,\n",
    "                    nb_abstract_obs,\n",
    "                    false,\n",
    "                    Vector{Float64}(),\n",
    "                    epsilon)\n",
    "fsc = InitFSC(max_b_gap, planner._max_graph_node_size, action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- 2: Graph Search ---\n",
    "Search(pomdp, particles_b0, dict_weighted_b0, fsc, planner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Simulate the computed FSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimulationFSC(b0, pomdp, fsc, discount(pomdp), planner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate the computed FSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_eval = 100000\n",
    "EvaluationWithSimulationFSC(pomdp, fsc, discount(pomdp), nb_eval, planner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
