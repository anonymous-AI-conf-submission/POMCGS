{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Install Julia and POMDP.jl\n",
    "\n",
    "Please first install Julia and POMDP.jl (https://github.com/JuliaPOMDP/POMDPs.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Include Julia packages and load the problem\n",
    "Several POMDP julia packages such as \"POMDPTools, POMDPModels\" are already included in planner.jl.\n",
    "\n",
    "If there is an error about uninstalled packages, please install them with \"pkg.add()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "include(\"../ContinuousPOMCGS/Planner.jl\")\n",
    "using Plots\n",
    "using LaserTag\n",
    "\n",
    "# --- Laser Tag ---\n",
    "rng = MersenneTwister(7)\n",
    "# println(discount(pomdp))\n",
    "pomdp = gen_lasertag(rng=rng, robot_position_known=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0.1: Parameters ---\n",
    "## This is an exmaple parameter configuraiton ##\n",
    "b0 = initialstate(pomdp) # Get POMDP's initial belief\n",
    "nb_process_samples = 10000\n",
    "max_b_gap = 0.3\n",
    "nb_particles_b0 = nb_process_samples\n",
    "c = 1.0\n",
    "nb_abstract_obs = 5\n",
    "epsilon = 0.1\n",
    "particles_b0, dict_weighted_b0 = InitContinuousActionPOMDP(pomdp, b0, nb_particles_b0)\n",
    "rmin, a_rmin = FindRLower(pomdp, b0, action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare $V_{mdp}$\n",
    "\n",
    "Here we use a Q-learning algorithm to compute $V_{MDP}$, one can also use other MDP solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Q learning parameters\n",
    "Q_table = Dict{Any, Dict{Int64, Float64}}()\n",
    "learning_rate = 0.9\n",
    "explore_rate = 0.6\n",
    "\n",
    "\n",
    "Q_learning_policy = Qlearning(Q_table, learning_rate, explore_rate, action_space)\n",
    "\n",
    "# --- 0.2: Prepare Rollout Policy ---\n",
    "nb_episode_size = 30\n",
    "nb_max_episode = 10\n",
    "nb_sim = 500\n",
    "epsilon = 0.01\n",
    "Training(Q_learning_policy, nb_episode_size, nb_max_episode, nb_sim, epsilon, particles_b0, pomdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1: Define POMCGS and fsc ---\n",
    "planner = ContinuousPlannerPOMCGS(rmin, Vmdp)\n",
    "# planner._bool_PCA_observation = true # if one want to test with PCA dimension reduction\n",
    "InitPlannerParameters(planner, \n",
    "                    nb_process_samples, \n",
    "                    max_b_gap,\n",
    "                    c,\n",
    "                    discount(pomdp),\n",
    "                    nb_abstract_obs,\n",
    "                    false,\n",
    "                    Vector{Float64}(),\n",
    "                    epsilon)\n",
    "fsc = InitFSC(max_b_gap, max_node_size, action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Init POMCGS and run the solver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- 2: Graph Search ---\n",
    "Search(pomdp, particles_b0, dict_weighted_b0, fsc, planner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
